{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppaunovski/vvmn_graph_mixer/blob/master/GraphMixer_tryout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgRtGqNooTQA",
        "outputId": "2155259c-c96a-42ff-902d-1119b894d399"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.0+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-spline-conv\n",
            "  Downloading torch_spline_conv-1.2.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Building wheels for collected packages: torch-scatter, torch-sparse, torch-cluster, torch-spline-conv\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=507268 sha256=da6e3ecf54e06722cb3077918cb4a5ae608ca0226667e90f7407d5ab9876cc38\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl size=1092566 sha256=d1988cf24e2cc19d996dbaaf0f0c60be3f2bbec3bf445fc773536a6d4e3faa0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/dd/0f/a6a16f9f3b0236733d257b4b4ea91b548b984a341ed3b8f38c\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.6.3-cp310-cp310-linux_x86_64.whl size=722828 sha256=4fe3641e1c316b5efaf09a63b3a1caae9bf0110b273c1b75987e2e39c83f0902\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/78/c3/536637b3cdcc3313aa5e8851a6c72b97f6a01877e68c7595e3\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.2.2-cp310-cp310-linux_x86_64.whl size=207810 sha256=972c39dfb9da1f81e3ecd32fcc4d86ad7fa4c125a3f199ecf4af4ee905440080\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/34/be/187e4b5f5ccefecca2c1a5dfc8da244ec50baa1f33c7b8c9a1\n",
            "Successfully built torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster, torch-geometric\n",
            "Successfully installed torch-cluster-1.6.3 torch-geometric-2.5.3 torch-scatter-2.1.2 torch-sparse-0.6.18 torch-spline-conv-1.2.2\n",
            "Collecting pybind11\n",
            "  Downloading pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.0/235.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.12.0\n"
          ]
        }
      ],
      "source": [
        "# pytorch\n",
        "! pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "\n",
        "# pytorch-geometric\n",
        "! pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cu116.html\n",
        "\n",
        "# pybind11 (used for c++ sampler)\n",
        "! pip install pybind11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YbkOFCZslPn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "\n",
        "################################################################################################\n",
        "################################################################################################\n",
        "################################################################################################\n",
        "\n",
        "def compute_ap_score(pred_pos, pred_neg, neg_samples):\n",
        "        y_pred = torch.cat([pred_pos, pred_neg], dim=0).sigmoid().cpu().detach()\n",
        "        y_true = torch.cat([torch.ones_like(pred_pos), torch.zeros_like(pred_neg)], dim=0).cpu().detach()\n",
        "        acc = average_precision_score(y_true, y_pred)\n",
        "        if neg_samples > 1:\n",
        "            auc = torch.sum(pred_pos.squeeze() < pred_neg.squeeze().reshape(neg_samples, -1), dim=0)\n",
        "            auc = 1 / (auc+1)\n",
        "        else:\n",
        "            auc = roc_auc_score(y_true, y_pred)\n",
        "        return acc, auc\n",
        "\n",
        "################################################################################################\n",
        "################################################################################################\n",
        "################################################################################################\n",
        "\"\"\"\n",
        "Module: Time-encoder\n",
        "\"\"\"\n",
        "\n",
        "class TimeEncode(nn.Module):\n",
        "    \"\"\"\n",
        "    out = linear(time_scatter): 1-->time_dims\n",
        "    out = cos(out)\n",
        "    \"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super(TimeEncode, self).__init__()\n",
        "        self.dim = dim\n",
        "        self.w = nn.Linear(1, dim)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self, ):\n",
        "        self.w.weight = nn.Parameter((torch.from_numpy(1 / 10 ** np.linspace(0, 9, self.dim, dtype=np.float32))).reshape(self.dim, -1))\n",
        "        self.w.bias = nn.Parameter(torch.zeros(self.dim))\n",
        "\n",
        "        self.w.weight.requires_grad = False\n",
        "        self.w.bias.requires_grad = False\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(self, t):\n",
        "        output = torch.cos(self.w(t.reshape((-1, 1))))\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "################################################################################################\n",
        "################################################################################################\n",
        "################################################################################################\n",
        "\"\"\"\n",
        "Module: MLP-Mixer\n",
        "\"\"\"\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    2-layer MLP with GeLU (fancy version of ReLU) as activation\n",
        "    \"\"\"\n",
        "    def __init__(self, dims, expansion_factor, dropout=0, use_single_layer=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dims = dims\n",
        "        self.use_single_layer = use_single_layer\n",
        "\n",
        "        self.expansion_factor = expansion_factor\n",
        "        self.dropout = dropout\n",
        "\n",
        "        if use_single_layer:\n",
        "            self.linear_0 = nn.Linear(dims, dims)\n",
        "        else:\n",
        "            self.linear_0 = nn.Linear(dims, int(expansion_factor * dims))\n",
        "            self.linear_1 = nn.Linear(int(expansion_factor * dims), dims)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.linear_0.reset_parameters()\n",
        "        if self.use_single_layer==False:\n",
        "            self.linear_1.reset_parameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_0(x)\n",
        "        x = F.gelu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        if self.use_single_layer==False:\n",
        "            x = self.linear_1(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        return x\n",
        "\n",
        "class MixerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    out = X.T + MLP_Layernorm(X.T)     # apply token mixing\n",
        "    out = out.T + MLP_Layernorm(out.T) # apply channel mixing\n",
        "    \"\"\"\n",
        "    def __init__(self, per_graph_size, dims,\n",
        "                 token_expansion_factor=0.5,\n",
        "                 channel_expansion_factor=4,\n",
        "                 dropout=0,\n",
        "                 module_spec=None, use_single_layer=False):\n",
        "        super().__init__()\n",
        "\n",
        "        if module_spec == None:\n",
        "            self.module_spec = ['token', 'channel']\n",
        "        else:\n",
        "            self.module_spec = module_spec.split('+')\n",
        "\n",
        "        if 'token' in self.module_spec:\n",
        "            self.token_layernorm = nn.LayerNorm(dims)\n",
        "            self.token_forward = FeedForward(per_graph_size, token_expansion_factor, dropout, use_single_layer)\n",
        "\n",
        "        if 'channel' in self.module_spec:\n",
        "            self.channel_layernorm = nn.LayerNorm(dims)\n",
        "            self.channel_forward = FeedForward(dims, channel_expansion_factor, dropout, use_single_layer)\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        if 'token' in self.module_spec:\n",
        "            self.token_layernorm.reset_parameters()\n",
        "            self.token_forward.reset_parameters()\n",
        "\n",
        "        if 'channel' in self.module_spec:\n",
        "            self.channel_layernorm.reset_parameters()\n",
        "            self.channel_forward.reset_parameters()\n",
        "\n",
        "    def token_mixer(self, x):\n",
        "        x = self.token_layernorm(x).permute(0, 2, 1)\n",
        "        x = self.token_forward(x).permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "    def channel_mixer(self, x):\n",
        "        x = self.channel_layernorm(x)\n",
        "        x = self.channel_forward(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        if 'token' in self.module_spec:\n",
        "            x = x + self.token_mixer(x)\n",
        "        if 'channel' in self.module_spec:\n",
        "            x = x + self.channel_mixer(x)\n",
        "        return x\n",
        "\n",
        "class FeatEncode(nn.Module):\n",
        "    \"\"\"\n",
        "    Return [raw_edge_feat | TimeEncode(edge_time_stamp)]\n",
        "    \"\"\"\n",
        "    def __init__(self, time_dims, feat_dims, out_dims):\n",
        "        super().__init__()\n",
        "\n",
        "        self.time_encoder = TimeEncode(time_dims)\n",
        "        self.feat_encoder = nn.Linear(time_dims + feat_dims, out_dims)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.time_encoder.reset_parameters()\n",
        "        self.feat_encoder.reset_parameters()\n",
        "\n",
        "    def forward(self, edge_feats, edge_ts):\n",
        "        edge_time_feats = self.time_encoder(edge_ts)\n",
        "        x = torch.cat([edge_feats, edge_time_feats], dim=1)\n",
        "        return self.feat_encoder(x)\n",
        "\n",
        "class MLPMixer(nn.Module):\n",
        "    \"\"\"\n",
        "    Input : [ batch_size, graph_size, edge_dims+time_dims]\n",
        "    Output: [ batch_size, graph_size, output_dims]\n",
        "    \"\"\"\n",
        "    def __init__(self, per_graph_size, time_channels,\n",
        "                 input_channels, hidden_channels, out_channels,\n",
        "                 num_layers=2, dropout=0.5,\n",
        "                 token_expansion_factor=0.5,\n",
        "                 channel_expansion_factor=4,\n",
        "                 module_spec=None, use_single_layer=False\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.per_graph_size = per_graph_size\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # input & output classifer\n",
        "        self.feat_encoder = FeatEncode(time_channels, input_channels, hidden_channels)\n",
        "        self.layernorm = nn.LayerNorm(hidden_channels)\n",
        "        self.mlp_head = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "        # inner layers\n",
        "        self.mixer_blocks = torch.nn.ModuleList()\n",
        "        for ell in range(num_layers):\n",
        "            if module_spec is None:\n",
        "                self.mixer_blocks.append(\n",
        "                    MixerBlock(per_graph_size, hidden_channels,\n",
        "                               token_expansion_factor,\n",
        "                               channel_expansion_factor,\n",
        "                               dropout, module_spec=None,\n",
        "                               use_single_layer=use_single_layer)\n",
        "                )\n",
        "            else:\n",
        "                self.mixer_blocks.append(\n",
        "                    MixerBlock(per_graph_size, hidden_channels,\n",
        "                               token_expansion_factor,\n",
        "                               channel_expansion_factor,\n",
        "                               dropout, module_spec=module_spec[ell],\n",
        "                               use_single_layer=use_single_layer)\n",
        "                )\n",
        "\n",
        "\n",
        "\n",
        "        # init\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for layer in self.mixer_blocks:\n",
        "            layer.reset_parameters()\n",
        "        self.feat_encoder.reset_parameters()\n",
        "        self.layernorm.reset_parameters()\n",
        "        self.mlp_head.reset_parameters()\n",
        "\n",
        "    def forward(self, edge_feats, edge_ts, batch_size, inds):\n",
        "        # x :     [ batch_size, graph_size, edge_dims+time_dims]\n",
        "        edge_time_feats = self.feat_encoder(edge_feats, edge_ts)\n",
        "        x = torch.zeros((batch_size * self.per_graph_size,\n",
        "                         edge_time_feats.size(1))).to(edge_feats.device)\n",
        "        x[inds] = x[inds] + edge_time_feats\n",
        "        x = torch.split(x, self.per_graph_size)\n",
        "        x = torch.stack(x)\n",
        "\n",
        "        # apply to original feats\n",
        "        for i in range(self.num_layers):\n",
        "            # apply to channel + feat dim\n",
        "            x = self.mixer_blocks[i](x)\n",
        "        x = self.layernorm(x)\n",
        "        x = torch.mean(x, dim=1)\n",
        "        x = self.mlp_head(x)\n",
        "        return x\n",
        "\n",
        "################################################################################################\n",
        "################################################################################################\n",
        "################################################################################################\n",
        "\n",
        "\"\"\"\n",
        "Edge predictor\n",
        "\"\"\"\n",
        "\n",
        "class EdgePredictor_per_node(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    out = linear(src_node_feats) + linear(dst_node_feats)\n",
        "    out = ReLU(out)\n",
        "    \"\"\"\n",
        "    def __init__(self, dim_in_time, dim_in_node):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dim_in_time = dim_in_time\n",
        "        self.dim_in_node = dim_in_node\n",
        "\n",
        "        self.src_fc = torch.nn.Linear(dim_in_time + dim_in_node, 100)\n",
        "        self.dst_fc = torch.nn.Linear(dim_in_time + dim_in_node, 100)\n",
        "        self.out_fc = torch.nn.Linear(100, 1)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self, ):\n",
        "        self.src_fc.reset_parameters()\n",
        "        self.dst_fc.reset_parameters()\n",
        "        self.out_fc.reset_parameters()\n",
        "\n",
        "    def forward(self, h, neg_samples=1):\n",
        "        num_edge = h.shape[0] // (neg_samples + 2)\n",
        "        h_src = self.src_fc(h[:num_edge])\n",
        "        h_pos_dst = self.dst_fc(h[num_edge:2 * num_edge])\n",
        "        h_neg_dst = self.dst_fc(h[2 * num_edge:])\n",
        "        h_pos_edge = torch.nn.functional.relu(h_src + h_pos_dst)\n",
        "        h_neg_edge = torch.nn.functional.relu(h_src.tile(neg_samples, 1) + h_neg_dst)\n",
        "        # h_pos_edge = torch.nn.functional.relu(h_pos_dst)\n",
        "        # h_neg_edge = torch.nn.functional.relu(h_neg_dst)\n",
        "        return self.out_fc(h_pos_edge), self.out_fc(h_neg_edge)\n",
        "\n",
        "class Mixer_per_node(nn.Module):\n",
        "    \"\"\"\n",
        "    Wrapper of MLPMixer and EdgePredictor\n",
        "    \"\"\"\n",
        "    def __init__(self, mlp_mixer_configs, edge_predictor_configs):\n",
        "        super(Mixer_per_node, self).__init__()\n",
        "\n",
        "        self.time_feats_dim = edge_predictor_configs['dim_in_time']\n",
        "        self.node_feats_dim = edge_predictor_configs['dim_in_node']\n",
        "\n",
        "        if self.time_feats_dim > 0:\n",
        "            self.base_model = MLPMixer(**mlp_mixer_configs)\n",
        "\n",
        "        self.edge_predictor = EdgePredictor_per_node(**edge_predictor_configs)\n",
        "\n",
        "        self.creterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        if self.time_feats_dim > 0:\n",
        "            self.base_model.reset_parameters()\n",
        "        self.edge_predictor.reset_parameters()\n",
        "\n",
        "    def forward(self, model_inputs, has_temporal_neighbors, neg_samples, node_feats):\n",
        "        pred_pos, pred_neg = self.predict(model_inputs, has_temporal_neighbors, neg_samples, node_feats)\n",
        "\n",
        "        pos_mask, neg_mask = self.pos_neg_mask(has_temporal_neighbors, neg_samples)\n",
        "        loss_pos = self.creterion(pred_pos, torch.ones_like(pred_pos))[pos_mask].mean()\n",
        "        loss_neg = self.creterion(pred_neg, torch.zeros_like(pred_neg))[neg_mask].mean()\n",
        "\n",
        "        # compute roc and precision score\n",
        "        acc, auc  = compute_ap_score(pred_pos, pred_neg, neg_samples)\n",
        "        return loss_pos + loss_neg, acc, auc\n",
        "\n",
        "    def predict(self, model_inputs, has_temporal_neighbors, neg_samples, node_feats):\n",
        "\n",
        "        if self.time_feats_dim > 0 and self.node_feats_dim == 0:\n",
        "            x = self.base_model(*model_inputs)\n",
        "        elif self.time_feats_dim > 0 and self.node_feats_dim > 0:\n",
        "            x = self.base_model(*model_inputs)\n",
        "            x = torch.cat([x, node_feats], dim=1)\n",
        "        elif self.time_feats_dim == 0 and self.node_feats_dim > 0:\n",
        "            x = node_feats\n",
        "        else:\n",
        "            print('Either time_feats_dim or node_feats_dim must larger than 0!')\n",
        "\n",
        "        pred_pos, pred_neg = self.edge_predictor(x, neg_samples=neg_samples)\n",
        "        return pred_pos, pred_neg\n",
        "\n",
        "    def pos_neg_mask(self, mask, neg_samples):\n",
        "        num_edge = len(mask) // (neg_samples + 2)\n",
        "        src_mask = mask[:num_edge]\n",
        "        pos_dst_mask = mask[num_edge:2 * num_edge]\n",
        "        neg_dst_mask = mask[2 * num_edge:]\n",
        "\n",
        "        pos_mask = [(i and j) for i,j in zip(src_mask, pos_dst_mask)]\n",
        "        neg_mask = [(i and j) for i,j in zip(src_mask * neg_samples, neg_dst_mask)]\n",
        "        return pos_mask, neg_mask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################################################################################\n",
        "################################################################################################\n",
        "################################################################################################\n",
        "\n",
        "\"\"\"\n",
        "Module: Node classifier\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class NodeClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, dim_in, dim_hid, num_class):\n",
        "        super(NodeClassificationModel, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(dim_in, dim_hid)\n",
        "        self.fc2 = torch.nn.Linear(dim_hid, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = torch.nn.functional.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeWZckub5M6/gAU+ZpmaI3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}